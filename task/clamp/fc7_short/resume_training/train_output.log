nohup: ignoring input
I1015 04:18:58.707242 22464 caffe.cpp:100] Use GPU with device ID 0
I1015 04:18:58.985661 22464 caffe.cpp:108] Starting Optimization
I1015 04:18:58.985803 22464 solver.cpp:32] Initializing solver from parameters: 
test_iter: 8
test_interval: 1
base_lr: 1e-05
display: 1
max_iter: 200
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 700
snapshot: 100
snapshot_prefix: "task/clamp/fc7_short/resume_training"
solver_mode: GPU
test_compute_loss: true
net: "task/clamp/train_val.prototxt"
I1015 04:18:58.985837 22464 solver.cpp:67] Creating training net from net file: task/clamp/train_val.prototxt
I1015 04:18:58.986793 22464 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1015 04:18:58.986830 22464 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1015 04:18:58.987109 22464 net.cpp:39] Initializing net from parameters: 
name: "ClampCaffeNet"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "data/clamp/train.txt"
    batch_size: 256
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/homes/ad6813/data/controlpoint_mean_256-227.binaryproto"
  }
}
layers {
  bottom: "data"
  top: "conv1"
  name: "conv1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1"
  top: "conv1"
  name: "relu1"
  type: RELU
}
layers {
  bottom: "conv1"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "norm1"
  name: "norm1"
  type: LRN
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layers {
  bottom: "norm1"
  top: "conv2"
  name: "conv2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "conv2"
  top: "conv2"
  name: "relu2"
  type: RELU
}
layers {
  bottom: "conv2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "norm2"
  name: "norm2"
  type: LRN
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layers {
  bottom: "norm2"
  top: "conv3"
  name: "conv3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3"
  top: "conv3"
  name: "relu3"
  type: RELU
}
layers {
  bottom: "conv3"
  top: "conv4"
  name: "conv4"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "conv4"
  top: "conv4"
  name: "relu4"
  type: RELU
}
layers {
  bottom: "conv4"
  top: "conv5"
  name: "conv5"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "conv5"
  top: "conv5"
  name: "relu5"
  type: RELU
}
layers {
  bottom: "conv5"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_clamp"
  name: "fc8_clamp"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_clamp"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1015 04:18:58.987256 22464 net.cpp:67] Creating Layer data
I1015 04:18:58.987269 22464 net.cpp:356] data -> data
I1015 04:18:58.987292 22464 net.cpp:356] data -> label
I1015 04:18:58.987315 22464 net.cpp:96] Setting up data
I1015 04:18:58.987325 22464 image_data_layer.cpp:30] Opening file data/clamp/train.txt
I1015 04:18:59.001204 22464 image_data_layer.cpp:45] A total of 23495 images.
I1015 04:18:59.007966 22464 image_data_layer.cpp:73] output data size: 256,3,227,227
I1015 04:18:59.008007 22464 base_data_layer.cpp:36] Loading mean file from/homes/ad6813/data/controlpoint_mean_256-227.binaryproto
I1015 04:18:59.038288 22464 net.cpp:103] Top shape: 256 3 227 227 (39574272)
I1015 04:18:59.038321 22464 net.cpp:103] Top shape: 256 1 1 1 (256)
I1015 04:18:59.038346 22464 net.cpp:67] Creating Layer conv1
I1015 04:18:59.038352 22464 net.cpp:394] conv1 <- data
I1015 04:18:59.038370 22464 net.cpp:356] conv1 -> conv1
I1015 04:18:59.038386 22464 net.cpp:96] Setting up conv1
I1015 04:18:59.039839 22464 net.cpp:103] Top shape: 256 96 55 55 (74342400)
I1015 04:18:59.039870 22464 net.cpp:67] Creating Layer relu1
I1015 04:18:59.039877 22464 net.cpp:394] relu1 <- conv1
I1015 04:18:59.039885 22464 net.cpp:345] relu1 -> conv1 (in-place)
I1015 04:18:59.039893 22464 net.cpp:96] Setting up relu1
I1015 04:18:59.039903 22464 net.cpp:103] Top shape: 256 96 55 55 (74342400)
I1015 04:18:59.039911 22464 net.cpp:67] Creating Layer pool1
I1015 04:18:59.039916 22464 net.cpp:394] pool1 <- conv1
I1015 04:18:59.039922 22464 net.cpp:356] pool1 -> pool1
I1015 04:18:59.039930 22464 net.cpp:96] Setting up pool1
I1015 04:18:59.039945 22464 net.cpp:103] Top shape: 256 96 27 27 (17915904)
I1015 04:18:59.039957 22464 net.cpp:67] Creating Layer norm1
I1015 04:18:59.039965 22464 net.cpp:394] norm1 <- pool1
I1015 04:18:59.039973 22464 net.cpp:356] norm1 -> norm1
I1015 04:18:59.039989 22464 net.cpp:96] Setting up norm1
I1015 04:18:59.040006 22464 net.cpp:103] Top shape: 256 96 27 27 (17915904)
I1015 04:18:59.040030 22464 net.cpp:67] Creating Layer conv2
I1015 04:18:59.040042 22464 net.cpp:394] conv2 <- norm1
I1015 04:18:59.040057 22464 net.cpp:356] conv2 -> conv2
I1015 04:18:59.040082 22464 net.cpp:96] Setting up conv2
I1015 04:18:59.052127 22464 net.cpp:103] Top shape: 256 256 27 27 (47775744)
I1015 04:18:59.052160 22464 net.cpp:67] Creating Layer relu2
I1015 04:18:59.052170 22464 net.cpp:394] relu2 <- conv2
I1015 04:18:59.052184 22464 net.cpp:345] relu2 -> conv2 (in-place)
I1015 04:18:59.052199 22464 net.cpp:96] Setting up relu2
I1015 04:18:59.052208 22464 net.cpp:103] Top shape: 256 256 27 27 (47775744)
I1015 04:18:59.052222 22464 net.cpp:67] Creating Layer pool2
I1015 04:18:59.052245 22464 net.cpp:394] pool2 <- conv2
I1015 04:18:59.052259 22464 net.cpp:356] pool2 -> pool2
I1015 04:18:59.052284 22464 net.cpp:96] Setting up pool2
I1015 04:18:59.052296 22464 net.cpp:103] Top shape: 256 256 13 13 (11075584)
I1015 04:18:59.052312 22464 net.cpp:67] Creating Layer norm2
I1015 04:18:59.052361 22464 net.cpp:394] norm2 <- pool2
I1015 04:18:59.052384 22464 net.cpp:356] norm2 -> norm2
I1015 04:18:59.052407 22464 net.cpp:96] Setting up norm2
I1015 04:18:59.052423 22464 net.cpp:103] Top shape: 256 256 13 13 (11075584)
I1015 04:18:59.052440 22464 net.cpp:67] Creating Layer conv3
I1015 04:18:59.052460 22464 net.cpp:394] conv3 <- norm2
I1015 04:18:59.052476 22464 net.cpp:356] conv3 -> conv3
I1015 04:18:59.052501 22464 net.cpp:96] Setting up conv3
I1015 04:18:59.087363 22464 net.cpp:103] Top shape: 256 384 13 13 (16613376)
I1015 04:18:59.087414 22464 net.cpp:67] Creating Layer relu3
I1015 04:18:59.087425 22464 net.cpp:394] relu3 <- conv3
I1015 04:18:59.087440 22464 net.cpp:345] relu3 -> conv3 (in-place)
I1015 04:18:59.087457 22464 net.cpp:96] Setting up relu3
I1015 04:18:59.087467 22464 net.cpp:103] Top shape: 256 384 13 13 (16613376)
I1015 04:18:59.087483 22464 net.cpp:67] Creating Layer conv4
I1015 04:18:59.087493 22464 net.cpp:394] conv4 <- conv3
I1015 04:18:59.087509 22464 net.cpp:356] conv4 -> conv4
I1015 04:18:59.087525 22464 net.cpp:96] Setting up conv4
I1015 04:18:59.113996 22464 net.cpp:103] Top shape: 256 384 13 13 (16613376)
I1015 04:18:59.114039 22464 net.cpp:67] Creating Layer relu4
I1015 04:18:59.114051 22464 net.cpp:394] relu4 <- conv4
I1015 04:18:59.114065 22464 net.cpp:345] relu4 -> conv4 (in-place)
I1015 04:18:59.114081 22464 net.cpp:96] Setting up relu4
I1015 04:18:59.114091 22464 net.cpp:103] Top shape: 256 384 13 13 (16613376)
I1015 04:18:59.114107 22464 net.cpp:67] Creating Layer conv5
I1015 04:18:59.114117 22464 net.cpp:394] conv5 <- conv4
I1015 04:18:59.114132 22464 net.cpp:356] conv5 -> conv5
I1015 04:18:59.114150 22464 net.cpp:96] Setting up conv5
I1015 04:18:59.131652 22464 net.cpp:103] Top shape: 256 256 13 13 (11075584)
I1015 04:18:59.131693 22464 net.cpp:67] Creating Layer relu5
I1015 04:18:59.131705 22464 net.cpp:394] relu5 <- conv5
I1015 04:18:59.131732 22464 net.cpp:345] relu5 -> conv5 (in-place)
I1015 04:18:59.131753 22464 net.cpp:96] Setting up relu5
I1015 04:18:59.131767 22464 net.cpp:103] Top shape: 256 256 13 13 (11075584)
I1015 04:18:59.131783 22464 net.cpp:67] Creating Layer pool5
I1015 04:18:59.131793 22464 net.cpp:394] pool5 <- conv5
I1015 04:18:59.131817 22464 net.cpp:356] pool5 -> pool5
I1015 04:18:59.131836 22464 net.cpp:96] Setting up pool5
I1015 04:18:59.131862 22464 net.cpp:103] Top shape: 256 256 6 6 (2359296)
I1015 04:18:59.131889 22464 net.cpp:67] Creating Layer fc6
I1015 04:18:59.131909 22464 net.cpp:394] fc6 <- pool5
I1015 04:18:59.131927 22464 net.cpp:356] fc6 -> fc6
I1015 04:18:59.131947 22464 net.cpp:96] Setting up fc6
I1015 04:19:00.603947 22464 net.cpp:103] Top shape: 256 4096 1 1 (1048576)
I1015 04:19:00.603996 22464 net.cpp:67] Creating Layer relu6
I1015 04:19:00.604008 22464 net.cpp:394] relu6 <- fc6
I1015 04:19:00.604022 22464 net.cpp:345] relu6 -> fc6 (in-place)
I1015 04:19:00.604038 22464 net.cpp:96] Setting up relu6
I1015 04:19:00.604050 22464 net.cpp:103] Top shape: 256 4096 1 1 (1048576)
I1015 04:19:00.604068 22464 net.cpp:67] Creating Layer drop6
I1015 04:19:00.604079 22464 net.cpp:394] drop6 <- fc6
I1015 04:19:00.604094 22464 net.cpp:345] drop6 -> fc6 (in-place)
I1015 04:19:00.604107 22464 net.cpp:96] Setting up drop6
I1015 04:19:00.604123 22464 net.cpp:103] Top shape: 256 4096 1 1 (1048576)
I1015 04:19:00.604156 22464 net.cpp:67] Creating Layer fc7
I1015 04:19:00.604167 22464 net.cpp:394] fc7 <- fc6
I1015 04:19:00.604183 22464 net.cpp:356] fc7 -> fc7
I1015 04:19:00.604208 22464 net.cpp:96] Setting up fc7
I1015 04:19:01.257345 22464 net.cpp:103] Top shape: 256 4096 1 1 (1048576)
I1015 04:19:01.257396 22464 net.cpp:67] Creating Layer relu7
I1015 04:19:01.257408 22464 net.cpp:394] relu7 <- fc7
I1015 04:19:01.257439 22464 net.cpp:345] relu7 -> fc7 (in-place)
I1015 04:19:01.257457 22464 net.cpp:96] Setting up relu7
I1015 04:19:01.257467 22464 net.cpp:103] Top shape: 256 4096 1 1 (1048576)
I1015 04:19:01.257488 22464 net.cpp:67] Creating Layer drop7
I1015 04:19:01.257499 22464 net.cpp:394] drop7 <- fc7
I1015 04:19:01.257513 22464 net.cpp:345] drop7 -> fc7 (in-place)
I1015 04:19:01.257529 22464 net.cpp:96] Setting up drop7
I1015 04:19:01.257550 22464 net.cpp:103] Top shape: 256 4096 1 1 (1048576)
I1015 04:19:01.257577 22464 net.cpp:67] Creating Layer fc8_clamp
I1015 04:19:01.257589 22464 net.cpp:394] fc8_clamp <- fc7
I1015 04:19:01.257609 22464 net.cpp:356] fc8_clamp -> fc8_clamp
I1015 04:19:01.257637 22464 net.cpp:96] Setting up fc8_clamp
I1015 04:19:01.257998 22464 net.cpp:103] Top shape: 256 2 1 1 (512)
I1015 04:19:01.258023 22464 net.cpp:67] Creating Layer loss
I1015 04:19:01.258039 22464 net.cpp:394] loss <- fc8_clamp
I1015 04:19:01.258051 22464 net.cpp:394] loss <- label
I1015 04:19:01.258070 22464 net.cpp:356] loss -> (automatic)
I1015 04:19:01.258085 22464 net.cpp:96] Setting up loss
I1015 04:19:01.258113 22464 net.cpp:103] Top shape: 1 1 1 1 (1)
I1015 04:19:01.258126 22464 net.cpp:109]     with loss weight 1
I1015 04:19:01.258216 22464 net.cpp:170] loss needs backward computation.
I1015 04:19:01.258229 22464 net.cpp:170] fc8_clamp needs backward computation.
I1015 04:19:01.258245 22464 net.cpp:172] drop7 does not need backward computation.
I1015 04:19:01.258255 22464 net.cpp:172] relu7 does not need backward computation.
I1015 04:19:01.258263 22464 net.cpp:172] fc7 does not need backward computation.
I1015 04:19:01.258272 22464 net.cpp:172] drop6 does not need backward computation.
I1015 04:19:01.258281 22464 net.cpp:172] relu6 does not need backward computation.
I1015 04:19:01.258296 22464 net.cpp:172] fc6 does not need backward computation.
I1015 04:19:01.258307 22464 net.cpp:172] pool5 does not need backward computation.
I1015 04:19:01.258317 22464 net.cpp:172] relu5 does not need backward computation.
I1015 04:19:01.258326 22464 net.cpp:172] conv5 does not need backward computation.
I1015 04:19:01.258334 22464 net.cpp:172] relu4 does not need backward computation.
I1015 04:19:01.258352 22464 net.cpp:172] conv4 does not need backward computation.
I1015 04:19:01.258360 22464 net.cpp:172] relu3 does not need backward computation.
I1015 04:19:01.258370 22464 net.cpp:172] conv3 does not need backward computation.
I1015 04:19:01.258380 22464 net.cpp:172] norm2 does not need backward computation.
I1015 04:19:01.258396 22464 net.cpp:172] pool2 does not need backward computation.
I1015 04:19:01.258407 22464 net.cpp:172] relu2 does not need backward computation.
I1015 04:19:01.258416 22464 net.cpp:172] conv2 does not need backward computation.
I1015 04:19:01.258425 22464 net.cpp:172] norm1 does not need backward computation.
I1015 04:19:01.258435 22464 net.cpp:172] pool1 does not need backward computation.
I1015 04:19:01.258453 22464 net.cpp:172] relu1 does not need backward computation.
I1015 04:19:01.258462 22464 net.cpp:172] conv1 does not need backward computation.
I1015 04:19:01.258472 22464 net.cpp:172] data does not need backward computation.
I1015 04:19:01.258510 22464 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1015 04:19:01.258528 22464 net.cpp:219] Network initialization done.
I1015 04:19:01.258538 22464 net.cpp:220] Memory required for data: 1756198916
I1015 04:19:01.259516 22464 solver.cpp:151] Creating test net (#0) specified by net file: task/clamp/train_val.prototxt
I1015 04:19:01.259588 22464 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1015 04:19:01.259881 22464 net.cpp:39] Initializing net from parameters: 
name: "ClampCaffeNet"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "data/clamp/val.txt"
    batch_size: 251
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/homes/ad6813/data/controlpoint_mean_256-227.binaryproto"
  }
}
layers {
  bottom: "data"
  top: "conv1"
  name: "conv1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1"
  top: "conv1"
  name: "relu1"
  type: RELU
}
layers {
  bottom: "conv1"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "norm1"
  name: "norm1"
  type: LRN
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layers {
  bottom: "norm1"
  top: "conv2"
  name: "conv2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "conv2"
  top: "conv2"
  name: "relu2"
  type: RELU
}
layers {
  bottom: "conv2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "norm2"
  name: "norm2"
  type: LRN
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layers {
  bottom: "norm2"
  top: "conv3"
  name: "conv3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3"
  top: "conv3"
  name: "relu3"
  type: RELU
}
layers {
  bottom: "conv3"
  top: "conv4"
  name: "conv4"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "conv4"
  top: "conv4"
  name: "relu4"
  type: RELU
}
layers {
  bottom: "conv4"
  top: "conv5"
  name: "conv5"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "conv5"
  top: "conv5"
  name: "relu5"
  type: RELU
}
layers {
  bottom: "conv5"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 0
  weight_decay: 0
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_clamp"
  name: "fc8_clamp"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_clamp"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_clamp"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1015 04:19:01.260202 22464 net.cpp:67] Creating Layer data
I1015 04:19:01.260221 22464 net.cpp:356] data -> data
I1015 04:19:01.260249 22464 net.cpp:356] data -> label
I1015 04:19:01.260267 22464 net.cpp:96] Setting up data
I1015 04:19:01.260284 22464 image_data_layer.cpp:30] Opening file data/clamp/val.txt
I1015 04:19:01.262522 22464 image_data_layer.cpp:45] A total of 2006 images.
I1015 04:19:01.265090 22464 image_data_layer.cpp:73] output data size: 251,3,227,227
I1015 04:19:01.265118 22464 base_data_layer.cpp:36] Loading mean file from/homes/ad6813/data/controlpoint_mean_256-227.binaryproto
I1015 04:19:01.293922 22464 net.cpp:103] Top shape: 251 3 227 227 (38801337)
I1015 04:19:01.293958 22464 net.cpp:103] Top shape: 251 1 1 1 (251)
I1015 04:19:01.293979 22464 net.cpp:67] Creating Layer label_data_1_split
I1015 04:19:01.293990 22464 net.cpp:394] label_data_1_split <- label
I1015 04:19:01.294005 22464 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1015 04:19:01.294028 22464 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1015 04:19:01.294047 22464 net.cpp:96] Setting up label_data_1_split
I1015 04:19:01.294075 22464 net.cpp:103] Top shape: 251 1 1 1 (251)
I1015 04:19:01.294088 22464 net.cpp:103] Top shape: 251 1 1 1 (251)
I1015 04:19:01.294106 22464 net.cpp:67] Creating Layer conv1
I1015 04:19:01.294116 22464 net.cpp:394] conv1 <- data
I1015 04:19:01.294133 22464 net.cpp:356] conv1 -> conv1
I1015 04:19:01.294168 22464 net.cpp:96] Setting up conv1
I1015 04:19:01.295696 22464 net.cpp:103] Top shape: 251 96 55 55 (72890400)
I1015 04:19:01.295728 22464 net.cpp:67] Creating Layer relu1
I1015 04:19:01.295743 22464 net.cpp:394] relu1 <- conv1
I1015 04:19:01.295758 22464 net.cpp:345] relu1 -> conv1 (in-place)
I1015 04:19:01.295773 22464 net.cpp:96] Setting up relu1
I1015 04:19:01.295783 22464 net.cpp:103] Top shape: 251 96 55 55 (72890400)
I1015 04:19:01.295799 22464 net.cpp:67] Creating Layer pool1
I1015 04:19:01.295814 22464 net.cpp:394] pool1 <- conv1
I1015 04:19:01.295836 22464 net.cpp:356] pool1 -> pool1
I1015 04:19:01.295855 22464 net.cpp:96] Setting up pool1
I1015 04:19:01.295868 22464 net.cpp:103] Top shape: 251 96 27 27 (17565984)
I1015 04:19:01.295891 22464 net.cpp:67] Creating Layer norm1
I1015 04:19:01.295900 22464 net.cpp:394] norm1 <- pool1
I1015 04:19:01.295914 22464 net.cpp:356] norm1 -> norm1
I1015 04:19:01.295936 22464 net.cpp:96] Setting up norm1
I1015 04:19:01.295951 22464 net.cpp:103] Top shape: 251 96 27 27 (17565984)
I1015 04:19:01.295969 22464 net.cpp:67] Creating Layer conv2
I1015 04:19:01.295990 22464 net.cpp:394] conv2 <- norm1
I1015 04:19:01.296010 22464 net.cpp:356] conv2 -> conv2
I1015 04:19:01.296033 22464 net.cpp:96] Setting up conv2
I1015 04:19:01.309090 22464 net.cpp:103] Top shape: 251 256 27 27 (46842624)
I1015 04:19:01.309123 22464 net.cpp:67] Creating Layer relu2
I1015 04:19:01.309134 22464 net.cpp:394] relu2 <- conv2
I1015 04:19:01.309150 22464 net.cpp:345] relu2 -> conv2 (in-place)
I1015 04:19:01.309165 22464 net.cpp:96] Setting up relu2
I1015 04:19:01.309176 22464 net.cpp:103] Top shape: 251 256 27 27 (46842624)
I1015 04:19:01.309192 22464 net.cpp:67] Creating Layer pool2
I1015 04:19:01.309201 22464 net.cpp:394] pool2 <- conv2
I1015 04:19:01.309218 22464 net.cpp:356] pool2 -> pool2
I1015 04:19:01.309244 22464 net.cpp:96] Setting up pool2
I1015 04:19:01.309262 22464 net.cpp:103] Top shape: 251 256 13 13 (10859264)
I1015 04:19:01.309275 22464 net.cpp:67] Creating Layer norm2
I1015 04:19:01.309293 22464 net.cpp:394] norm2 <- pool2
I1015 04:19:01.309311 22464 net.cpp:356] norm2 -> norm2
I1015 04:19:01.309340 22464 net.cpp:96] Setting up norm2
I1015 04:19:01.309351 22464 net.cpp:103] Top shape: 251 256 13 13 (10859264)
I1015 04:19:01.309393 22464 net.cpp:67] Creating Layer conv3
I1015 04:19:01.309407 22464 net.cpp:394] conv3 <- norm2
I1015 04:19:01.309434 22464 net.cpp:356] conv3 -> conv3
I1015 04:19:01.309455 22464 net.cpp:96] Setting up conv3
I1015 04:19:01.347455 22464 net.cpp:103] Top shape: 251 384 13 13 (16288896)
I1015 04:19:01.347509 22464 net.cpp:67] Creating Layer relu3
I1015 04:19:01.347522 22464 net.cpp:394] relu3 <- conv3
I1015 04:19:01.347535 22464 net.cpp:345] relu3 -> conv3 (in-place)
I1015 04:19:01.347553 22464 net.cpp:96] Setting up relu3
I1015 04:19:01.347563 22464 net.cpp:103] Top shape: 251 384 13 13 (16288896)
I1015 04:19:01.347579 22464 net.cpp:67] Creating Layer conv4
I1015 04:19:01.347589 22464 net.cpp:394] conv4 <- conv3
I1015 04:19:01.347611 22464 net.cpp:356] conv4 -> conv4
I1015 04:19:01.347633 22464 net.cpp:96] Setting up conv4
I1015 04:19:01.376097 22464 net.cpp:103] Top shape: 251 384 13 13 (16288896)
I1015 04:19:01.376140 22464 net.cpp:67] Creating Layer relu4
I1015 04:19:01.376152 22464 net.cpp:394] relu4 <- conv4
I1015 04:19:01.376170 22464 net.cpp:345] relu4 -> conv4 (in-place)
I1015 04:19:01.376188 22464 net.cpp:96] Setting up relu4
I1015 04:19:01.376199 22464 net.cpp:103] Top shape: 251 384 13 13 (16288896)
I1015 04:19:01.376214 22464 net.cpp:67] Creating Layer conv5
I1015 04:19:01.376224 22464 net.cpp:394] conv5 <- conv4
I1015 04:19:01.376242 22464 net.cpp:356] conv5 -> conv5
I1015 04:19:01.376260 22464 net.cpp:96] Setting up conv5
I1015 04:19:01.395200 22464 net.cpp:103] Top shape: 251 256 13 13 (10859264)
I1015 04:19:01.395237 22464 net.cpp:67] Creating Layer relu5
I1015 04:19:01.395248 22464 net.cpp:394] relu5 <- conv5
I1015 04:19:01.395265 22464 net.cpp:345] relu5 -> conv5 (in-place)
I1015 04:19:01.395282 22464 net.cpp:96] Setting up relu5
I1015 04:19:01.395292 22464 net.cpp:103] Top shape: 251 256 13 13 (10859264)
I1015 04:19:01.395311 22464 net.cpp:67] Creating Layer pool5
I1015 04:19:01.395324 22464 net.cpp:394] pool5 <- conv5
I1015 04:19:01.395339 22464 net.cpp:356] pool5 -> pool5
I1015 04:19:01.395364 22464 net.cpp:96] Setting up pool5
I1015 04:19:01.395382 22464 net.cpp:103] Top shape: 251 256 6 6 (2313216)
I1015 04:19:01.395409 22464 net.cpp:67] Creating Layer fc6
I1015 04:19:01.395426 22464 net.cpp:394] fc6 <- pool5
I1015 04:19:01.395440 22464 net.cpp:356] fc6 -> fc6
I1015 04:19:01.395472 22464 net.cpp:96] Setting up fc6
I1015 04:19:02.866669 22464 net.cpp:103] Top shape: 251 4096 1 1 (1028096)
I1015 04:19:02.866720 22464 net.cpp:67] Creating Layer relu6
I1015 04:19:02.866732 22464 net.cpp:394] relu6 <- fc6
I1015 04:19:02.866752 22464 net.cpp:345] relu6 -> fc6 (in-place)
I1015 04:19:02.866770 22464 net.cpp:96] Setting up relu6
I1015 04:19:02.866780 22464 net.cpp:103] Top shape: 251 4096 1 1 (1028096)
I1015 04:19:02.866793 22464 net.cpp:67] Creating Layer drop6
I1015 04:19:02.866803 22464 net.cpp:394] drop6 <- fc6
I1015 04:19:02.866816 22464 net.cpp:345] drop6 -> fc6 (in-place)
I1015 04:19:02.866835 22464 net.cpp:96] Setting up drop6
I1015 04:19:02.866847 22464 net.cpp:103] Top shape: 251 4096 1 1 (1028096)
I1015 04:19:02.866863 22464 net.cpp:67] Creating Layer fc7
I1015 04:19:02.866888 22464 net.cpp:394] fc7 <- fc6
I1015 04:19:02.866904 22464 net.cpp:356] fc7 -> fc7
I1015 04:19:02.866930 22464 net.cpp:96] Setting up fc7
I1015 04:19:03.520225 22464 net.cpp:103] Top shape: 251 4096 1 1 (1028096)
I1015 04:19:03.520272 22464 net.cpp:67] Creating Layer relu7
I1015 04:19:03.520284 22464 net.cpp:394] relu7 <- fc7
I1015 04:19:03.520303 22464 net.cpp:345] relu7 -> fc7 (in-place)
I1015 04:19:03.520318 22464 net.cpp:96] Setting up relu7
I1015 04:19:03.520335 22464 net.cpp:103] Top shape: 251 4096 1 1 (1028096)
I1015 04:19:03.520349 22464 net.cpp:67] Creating Layer drop7
I1015 04:19:03.520359 22464 net.cpp:394] drop7 <- fc7
I1015 04:19:03.520373 22464 net.cpp:345] drop7 -> fc7 (in-place)
I1015 04:19:03.520388 22464 net.cpp:96] Setting up drop7
I1015 04:19:03.520400 22464 net.cpp:103] Top shape: 251 4096 1 1 (1028096)
I1015 04:19:03.520414 22464 net.cpp:67] Creating Layer fc8_clamp
I1015 04:19:03.520457 22464 net.cpp:394] fc8_clamp <- fc7
I1015 04:19:03.520486 22464 net.cpp:356] fc8_clamp -> fc8_clamp
I1015 04:19:03.520514 22464 net.cpp:96] Setting up fc8_clamp
I1015 04:19:03.520884 22464 net.cpp:103] Top shape: 251 2 1 1 (502)
I1015 04:19:03.520908 22464 net.cpp:67] Creating Layer fc8_clamp_fc8_clamp_0_split
I1015 04:19:03.520920 22464 net.cpp:394] fc8_clamp_fc8_clamp_0_split <- fc8_clamp
I1015 04:19:03.520937 22464 net.cpp:356] fc8_clamp_fc8_clamp_0_split -> fc8_clamp_fc8_clamp_0_split_0
I1015 04:19:03.520959 22464 net.cpp:356] fc8_clamp_fc8_clamp_0_split -> fc8_clamp_fc8_clamp_0_split_1
I1015 04:19:03.521021 22464 net.cpp:96] Setting up fc8_clamp_fc8_clamp_0_split
I1015 04:19:03.521042 22464 net.cpp:103] Top shape: 251 2 1 1 (502)
I1015 04:19:03.521052 22464 net.cpp:103] Top shape: 251 2 1 1 (502)
I1015 04:19:03.521071 22464 net.cpp:67] Creating Layer loss
I1015 04:19:03.521085 22464 net.cpp:394] loss <- fc8_clamp_fc8_clamp_0_split_0
I1015 04:19:03.521098 22464 net.cpp:394] loss <- label_data_1_split_0
I1015 04:19:03.521123 22464 net.cpp:356] loss -> (automatic)
I1015 04:19:03.521137 22464 net.cpp:96] Setting up loss
I1015 04:19:03.521162 22464 net.cpp:103] Top shape: 1 1 1 1 (1)
I1015 04:19:03.521173 22464 net.cpp:109]     with loss weight 1
I1015 04:19:03.521209 22464 net.cpp:67] Creating Layer accuracy
I1015 04:19:03.521224 22464 net.cpp:394] accuracy <- fc8_clamp_fc8_clamp_0_split_1
I1015 04:19:03.521235 22464 net.cpp:394] accuracy <- label_data_1_split_1
I1015 04:19:03.521253 22464 net.cpp:356] accuracy -> accuracy
I1015 04:19:03.521280 22464 net.cpp:96] Setting up accuracy
I1015 04:19:03.521296 22464 net.cpp:103] Top shape: 1 1 1 1 (1)
I1015 04:19:03.521317 22464 net.cpp:172] accuracy does not need backward computation.
I1015 04:19:03.521327 22464 net.cpp:170] loss needs backward computation.
I1015 04:19:03.521337 22464 net.cpp:170] fc8_clamp_fc8_clamp_0_split needs backward computation.
I1015 04:19:03.521347 22464 net.cpp:170] fc8_clamp needs backward computation.
I1015 04:19:03.521363 22464 net.cpp:172] drop7 does not need backward computation.
I1015 04:19:03.521373 22464 net.cpp:172] relu7 does not need backward computation.
I1015 04:19:03.521383 22464 net.cpp:172] fc7 does not need backward computation.
I1015 04:19:03.521391 22464 net.cpp:172] drop6 does not need backward computation.
I1015 04:19:03.521401 22464 net.cpp:172] relu6 does not need backward computation.
I1015 04:19:03.521409 22464 net.cpp:172] fc6 does not need backward computation.
I1015 04:19:03.521420 22464 net.cpp:172] pool5 does not need backward computation.
I1015 04:19:03.521428 22464 net.cpp:172] relu5 does not need backward computation.
I1015 04:19:03.521438 22464 net.cpp:172] conv5 does not need backward computation.
I1015 04:19:03.521447 22464 net.cpp:172] relu4 does not need backward computation.
I1015 04:19:03.521456 22464 net.cpp:172] conv4 does not need backward computation.
I1015 04:19:03.521466 22464 net.cpp:172] relu3 does not need backward computation.
I1015 04:19:03.521474 22464 net.cpp:172] conv3 does not need backward computation.
I1015 04:19:03.521486 22464 net.cpp:172] norm2 does not need backward computation.
I1015 04:19:03.521494 22464 net.cpp:172] pool2 does not need backward computation.
I1015 04:19:03.521504 22464 net.cpp:172] relu2 does not need backward computation.
I1015 04:19:03.521513 22464 net.cpp:172] conv2 does not need backward computation.
I1015 04:19:03.521523 22464 net.cpp:172] norm1 does not need backward computation.
I1015 04:19:03.521577 22464 net.cpp:172] pool1 does not need backward computation.
I1015 04:19:03.521589 22464 net.cpp:172] relu1 does not need backward computation.
I1015 04:19:03.521606 22464 net.cpp:172] conv1 does not need backward computation.
I1015 04:19:03.521620 22464 net.cpp:172] label_data_1_split does not need backward computation.
I1015 04:19:03.521630 22464 net.cpp:172] data does not need backward computation.
I1015 04:19:03.521637 22464 net.cpp:208] This network produces output accuracy
I1015 04:19:03.521703 22464 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1015 04:19:03.521730 22464 net.cpp:219] Network initialization done.
I1015 04:19:03.521739 22464 net.cpp:220] Memory required for data: 1721904184
I1015 04:19:03.521880 22464 solver.cpp:41] Solver scaffolding done.
I1015 04:19:03.521895 22464 caffe.cpp:116] Finetuning from task/clamp/fc7_short_iter_500.caffemodel
I1015 04:19:04.020819 22464 solver.cpp:160] Solving ClampCaffeNet
I1015 04:19:04.020905 22464 solver.cpp:247] Iteration 0, Testing net (#0)
I1015 04:19:09.719318 22464 solver.cpp:285] Test loss: 0.24579
I1015 04:19:09.719383 22464 solver.cpp:298]     Test net output #0: accuracy = 0.908864
I1015 04:19:10.155392 22464 solver.cpp:191] Iteration 0, loss = 0.286487
I1015 04:19:10.155446 22464 solver.cpp:403] Iteration 0, lr = 1e-05
I1015 04:19:10.158049 22464 solver.cpp:247] Iteration 1, Testing net (#0)
I1015 04:19:15.879046 22464 solver.cpp:285] Test loss: 0.249137
I1015 04:19:15.879093 22464 solver.cpp:298]     Test net output #0: accuracy = 0.909861
I1015 04:19:16.302098 22464 solver.cpp:191] Iteration 1, loss = 0.29817
I1015 04:19:16.302145 22464 solver.cpp:403] Iteration 1, lr = 1e-05
I1015 04:19:16.302551 22464 solver.cpp:247] Iteration 2, Testing net (#0)
I1015 04:19:22.020599 22464 solver.cpp:285] Test loss: 0.249903
I1015 04:19:22.020650 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910359
I1015 04:19:22.448552 22464 solver.cpp:191] Iteration 2, loss = 0.241002
I1015 04:19:22.448600 22464 solver.cpp:403] Iteration 2, lr = 1e-05
I1015 04:19:22.449007 22464 solver.cpp:247] Iteration 3, Testing net (#0)
I1015 04:19:28.160127 22464 solver.cpp:285] Test loss: 0.247738
I1015 04:19:28.160174 22464 solver.cpp:298]     Test net output #0: accuracy = 0.909861
I1015 04:19:28.588197 22464 solver.cpp:191] Iteration 3, loss = 0.223177
I1015 04:19:28.588245 22464 solver.cpp:403] Iteration 3, lr = 1e-05
I1015 04:19:28.588676 22464 solver.cpp:247] Iteration 4, Testing net (#0)
I1015 04:19:34.290716 22464 solver.cpp:285] Test loss: 0.245405
I1015 04:19:34.290796 22464 solver.cpp:298]     Test net output #0: accuracy = 0.913347
I1015 04:19:34.719190 22464 solver.cpp:191] Iteration 4, loss = 0.307826
I1015 04:19:34.719236 22464 solver.cpp:403] Iteration 4, lr = 1e-05
I1015 04:19:34.719641 22464 solver.cpp:247] Iteration 5, Testing net (#0)
I1015 04:19:40.446259 22464 solver.cpp:285] Test loss: 0.248445
I1015 04:19:40.446305 22464 solver.cpp:298]     Test net output #0: accuracy = 0.913347
I1015 04:19:40.874033 22464 solver.cpp:191] Iteration 5, loss = 0.258165
I1015 04:19:40.874079 22464 solver.cpp:403] Iteration 5, lr = 1e-05
I1015 04:19:40.874481 22464 solver.cpp:247] Iteration 6, Testing net (#0)
I1015 04:19:46.593261 22464 solver.cpp:285] Test loss: 0.24513
I1015 04:19:46.593307 22464 solver.cpp:298]     Test net output #0: accuracy = 0.913347
I1015 04:19:47.021260 22464 solver.cpp:191] Iteration 6, loss = 0.310761
I1015 04:19:47.021304 22464 solver.cpp:403] Iteration 6, lr = 1e-05
I1015 04:19:47.021664 22464 solver.cpp:247] Iteration 7, Testing net (#0)
I1015 04:19:52.733106 22464 solver.cpp:285] Test loss: 0.24551
I1015 04:19:52.733152 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910857
I1015 04:19:53.160729 22464 solver.cpp:191] Iteration 7, loss = 0.21877
I1015 04:19:53.160774 22464 solver.cpp:403] Iteration 7, lr = 1e-05
I1015 04:19:53.161137 22464 solver.cpp:247] Iteration 8, Testing net (#0)
I1015 04:19:58.883549 22464 solver.cpp:285] Test loss: 0.247537
I1015 04:19:58.883595 22464 solver.cpp:298]     Test net output #0: accuracy = 0.909861
I1015 04:19:59.311512 22464 solver.cpp:191] Iteration 8, loss = 0.340426
I1015 04:19:59.311553 22464 solver.cpp:403] Iteration 8, lr = 1e-05
I1015 04:19:59.311908 22464 solver.cpp:247] Iteration 9, Testing net (#0)
I1015 04:20:05.012172 22464 solver.cpp:285] Test loss: 0.242721
I1015 04:20:05.012236 22464 solver.cpp:298]     Test net output #0: accuracy = 0.916335
I1015 04:20:05.439059 22464 solver.cpp:191] Iteration 9, loss = 0.333046
I1015 04:20:05.439103 22464 solver.cpp:403] Iteration 9, lr = 1e-05
I1015 04:20:05.439460 22464 solver.cpp:247] Iteration 10, Testing net (#0)
I1015 04:20:11.153342 22464 solver.cpp:285] Test loss: 0.245029
I1015 04:20:11.153388 22464 solver.cpp:298]     Test net output #0: accuracy = 0.915339
I1015 04:20:11.580258 22464 solver.cpp:191] Iteration 10, loss = 0.283186
I1015 04:20:11.580303 22464 solver.cpp:403] Iteration 10, lr = 1e-05
I1015 04:20:11.580682 22464 solver.cpp:247] Iteration 11, Testing net (#0)
I1015 04:20:17.288821 22464 solver.cpp:285] Test loss: 0.243137
I1015 04:20:17.288869 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912849
I1015 04:20:17.716223 22464 solver.cpp:191] Iteration 11, loss = 0.27482
I1015 04:20:17.716267 22464 solver.cpp:403] Iteration 11, lr = 1e-05
I1015 04:20:17.716641 22464 solver.cpp:247] Iteration 12, Testing net (#0)
I1015 04:20:23.420511 22464 solver.cpp:285] Test loss: 0.246473
I1015 04:20:23.420557 22464 solver.cpp:298]     Test net output #0: accuracy = 0.908865
I1015 04:20:23.848225 22464 solver.cpp:191] Iteration 12, loss = 0.290557
I1015 04:20:23.848270 22464 solver.cpp:403] Iteration 12, lr = 1e-05
I1015 04:20:23.848644 22464 solver.cpp:247] Iteration 13, Testing net (#0)
I1015 04:20:29.563606 22464 solver.cpp:285] Test loss: 0.242909
I1015 04:20:29.563649 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912849
I1015 04:20:29.991154 22464 solver.cpp:191] Iteration 13, loss = 0.242187
I1015 04:20:29.991199 22464 solver.cpp:403] Iteration 13, lr = 1e-05
I1015 04:20:29.991554 22464 solver.cpp:247] Iteration 14, Testing net (#0)
I1015 04:20:35.708065 22464 solver.cpp:285] Test loss: 0.244747
I1015 04:20:35.708134 22464 solver.cpp:298]     Test net output #0: accuracy = 0.914343
I1015 04:20:36.135975 22464 solver.cpp:191] Iteration 14, loss = 0.355418
I1015 04:20:36.136019 22464 solver.cpp:403] Iteration 14, lr = 1e-05
I1015 04:20:36.136409 22464 solver.cpp:247] Iteration 15, Testing net (#0)
I1015 04:20:41.841166 22464 solver.cpp:285] Test loss: 0.245676
I1015 04:20:41.841212 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912351
I1015 04:20:42.268651 22464 solver.cpp:191] Iteration 15, loss = 0.211944
I1015 04:20:42.268692 22464 solver.cpp:403] Iteration 15, lr = 1e-05
I1015 04:20:42.269065 22464 solver.cpp:247] Iteration 16, Testing net (#0)
I1015 04:20:47.994176 22464 solver.cpp:285] Test loss: 0.245205
I1015 04:20:47.994222 22464 solver.cpp:298]     Test net output #0: accuracy = 0.915339
I1015 04:20:48.421489 22464 solver.cpp:191] Iteration 16, loss = 0.27601
I1015 04:20:48.421532 22464 solver.cpp:403] Iteration 16, lr = 1e-05
I1015 04:20:48.421900 22464 solver.cpp:247] Iteration 17, Testing net (#0)
I1015 04:20:54.140175 22464 solver.cpp:285] Test loss: 0.243018
I1015 04:20:54.140219 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910359
I1015 04:20:54.567186 22464 solver.cpp:191] Iteration 17, loss = 0.236607
I1015 04:20:54.567229 22464 solver.cpp:403] Iteration 17, lr = 1e-05
I1015 04:20:54.567597 22464 solver.cpp:247] Iteration 18, Testing net (#0)
I1015 04:21:00.275495 22464 solver.cpp:285] Test loss: 0.243358
I1015 04:21:00.275538 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911853
I1015 04:21:00.703352 22464 solver.cpp:191] Iteration 18, loss = 0.257514
I1015 04:21:00.703397 22464 solver.cpp:403] Iteration 18, lr = 1e-05
I1015 04:21:00.703764 22464 solver.cpp:247] Iteration 19, Testing net (#0)
I1015 04:21:06.425391 22464 solver.cpp:285] Test loss: 0.244318
I1015 04:21:06.425456 22464 solver.cpp:298]     Test net output #0: accuracy = 0.913347
I1015 04:21:06.852063 22464 solver.cpp:191] Iteration 19, loss = 0.297193
I1015 04:21:06.852105 22464 solver.cpp:403] Iteration 19, lr = 1e-05
I1015 04:21:06.852495 22464 solver.cpp:247] Iteration 20, Testing net (#0)
I1015 04:21:12.568713 22464 solver.cpp:285] Test loss: 0.244011
I1015 04:21:12.568758 22464 solver.cpp:298]     Test net output #0: accuracy = 0.914841
I1015 04:21:12.995651 22464 solver.cpp:191] Iteration 20, loss = 0.301011
I1015 04:21:12.995695 22464 solver.cpp:403] Iteration 20, lr = 1e-05
I1015 04:21:12.996070 22464 solver.cpp:247] Iteration 21, Testing net (#0)
I1015 04:21:18.702910 22464 solver.cpp:285] Test loss: 0.246695
I1015 04:21:18.702955 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912849
I1015 04:21:19.128785 22464 solver.cpp:191] Iteration 21, loss = 0.215196
I1015 04:21:19.128828 22464 solver.cpp:403] Iteration 21, lr = 1e-05
I1015 04:21:19.129197 22464 solver.cpp:247] Iteration 22, Testing net (#0)
I1015 04:21:24.849716 22464 solver.cpp:285] Test loss: 0.240102
I1015 04:21:24.849761 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912351
I1015 04:21:25.277202 22464 solver.cpp:191] Iteration 22, loss = 0.191087
I1015 04:21:25.277246 22464 solver.cpp:403] Iteration 22, lr = 1e-05
I1015 04:21:25.277614 22464 solver.cpp:247] Iteration 23, Testing net (#0)
I1015 04:21:31.000561 22464 solver.cpp:285] Test loss: 0.248984
I1015 04:21:31.000605 22464 solver.cpp:298]     Test net output #0: accuracy = 0.913845
I1015 04:21:31.427804 22464 solver.cpp:191] Iteration 23, loss = 0.244548
I1015 04:21:31.427847 22464 solver.cpp:403] Iteration 23, lr = 1e-05
I1015 04:21:31.428215 22464 solver.cpp:247] Iteration 24, Testing net (#0)
I1015 04:21:37.132411 22464 solver.cpp:285] Test loss: 0.246187
I1015 04:21:37.132520 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911853
I1015 04:21:37.558958 22464 solver.cpp:191] Iteration 24, loss = 0.333337
I1015 04:21:37.559000 22464 solver.cpp:403] Iteration 24, lr = 1e-05
I1015 04:21:37.559370 22464 solver.cpp:247] Iteration 25, Testing net (#0)
I1015 04:21:43.270694 22464 solver.cpp:285] Test loss: 0.242023
I1015 04:21:43.270737 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911853
I1015 04:21:43.697221 22464 solver.cpp:191] Iteration 25, loss = 0.296344
I1015 04:21:43.697265 22464 solver.cpp:403] Iteration 25, lr = 1e-05
I1015 04:21:43.697636 22464 solver.cpp:247] Iteration 26, Testing net (#0)
I1015 04:21:49.411548 22464 solver.cpp:285] Test loss: 0.246698
I1015 04:21:49.411593 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910359
I1015 04:21:49.838560 22464 solver.cpp:191] Iteration 26, loss = 0.310611
I1015 04:21:49.838604 22464 solver.cpp:403] Iteration 26, lr = 1e-05
I1015 04:21:49.838973 22464 solver.cpp:247] Iteration 27, Testing net (#0)
I1015 04:21:55.543342 22464 solver.cpp:285] Test loss: 0.244147
I1015 04:21:55.543387 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911853
I1015 04:21:55.970464 22464 solver.cpp:191] Iteration 27, loss = 0.32032
I1015 04:21:55.970510 22464 solver.cpp:403] Iteration 27, lr = 1e-05
I1015 04:21:55.970880 22464 solver.cpp:247] Iteration 28, Testing net (#0)
I1015 04:22:01.695958 22464 solver.cpp:285] Test loss: 0.244407
I1015 04:22:01.696004 22464 solver.cpp:298]     Test net output #0: accuracy = 0.908865
I1015 04:22:02.122855 22464 solver.cpp:191] Iteration 28, loss = 0.225547
I1015 04:22:02.122898 22464 solver.cpp:403] Iteration 28, lr = 1e-05
I1015 04:22:02.123267 22464 solver.cpp:247] Iteration 29, Testing net (#0)
I1015 04:22:07.841645 22464 solver.cpp:285] Test loss: 0.243019
I1015 04:22:07.841709 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912351
I1015 04:22:08.267344 22464 solver.cpp:191] Iteration 29, loss = 0.331683
I1015 04:22:08.267386 22464 solver.cpp:403] Iteration 29, lr = 1e-05
I1015 04:22:08.267760 22464 solver.cpp:247] Iteration 30, Testing net (#0)
I1015 04:22:13.962218 22464 solver.cpp:285] Test loss: 0.242635
I1015 04:22:13.962263 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912351
I1015 04:22:14.388124 22464 solver.cpp:191] Iteration 30, loss = 0.263818
I1015 04:22:14.388167 22464 solver.cpp:403] Iteration 30, lr = 1e-05
I1015 04:22:14.388566 22464 solver.cpp:247] Iteration 31, Testing net (#0)
I1015 04:22:20.098737 22464 solver.cpp:285] Test loss: 0.249361
I1015 04:22:20.098783 22464 solver.cpp:298]     Test net output #0: accuracy = 0.908864
I1015 04:22:20.524072 22464 solver.cpp:191] Iteration 31, loss = 0.228171
I1015 04:22:20.524114 22464 solver.cpp:403] Iteration 31, lr = 1e-05
I1015 04:22:20.524507 22464 solver.cpp:247] Iteration 32, Testing net (#0)
I1015 04:22:26.235982 22464 solver.cpp:285] Test loss: 0.242977
I1015 04:22:26.236027 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910857
I1015 04:22:26.661743 22464 solver.cpp:191] Iteration 32, loss = 0.257627
I1015 04:22:26.661787 22464 solver.cpp:403] Iteration 32, lr = 1e-05
I1015 04:22:26.662155 22464 solver.cpp:247] Iteration 33, Testing net (#0)
I1015 04:22:32.358305 22464 solver.cpp:285] Test loss: 0.242052
I1015 04:22:32.358350 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910359
I1015 04:22:32.783417 22464 solver.cpp:191] Iteration 33, loss = 0.35388
I1015 04:22:32.783460 22464 solver.cpp:403] Iteration 33, lr = 1e-05
I1015 04:22:32.783833 22464 solver.cpp:247] Iteration 34, Testing net (#0)
I1015 04:22:38.503911 22464 solver.cpp:285] Test loss: 0.244444
I1015 04:22:38.503979 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911853
I1015 04:22:38.929781 22464 solver.cpp:191] Iteration 34, loss = 0.21632
I1015 04:22:38.929824 22464 solver.cpp:403] Iteration 34, lr = 1e-05
I1015 04:22:38.930193 22464 solver.cpp:247] Iteration 35, Testing net (#0)
I1015 04:22:44.648638 22464 solver.cpp:285] Test loss: 0.245319
I1015 04:22:44.648684 22464 solver.cpp:298]     Test net output #0: accuracy = 0.915837
I1015 04:22:45.073742 22464 solver.cpp:191] Iteration 35, loss = 0.209953
I1015 04:22:45.073784 22464 solver.cpp:403] Iteration 35, lr = 1e-05
I1015 04:22:45.074156 22464 solver.cpp:247] Iteration 36, Testing net (#0)
I1015 04:22:50.778183 22464 solver.cpp:285] Test loss: 0.247581
I1015 04:22:50.778226 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911853
I1015 04:22:51.203788 22464 solver.cpp:191] Iteration 36, loss = 0.268146
I1015 04:22:51.203830 22464 solver.cpp:403] Iteration 36, lr = 1e-05
I1015 04:22:51.204197 22464 solver.cpp:247] Iteration 37, Testing net (#0)
I1015 04:22:56.925148 22464 solver.cpp:285] Test loss: 0.246598
I1015 04:22:56.925194 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910359
I1015 04:22:57.350368 22464 solver.cpp:191] Iteration 37, loss = 0.357042
I1015 04:22:57.350410 22464 solver.cpp:403] Iteration 37, lr = 1e-05
I1015 04:22:57.350783 22464 solver.cpp:247] Iteration 38, Testing net (#0)
I1015 04:23:03.056534 22464 solver.cpp:285] Test loss: 0.244573
I1015 04:23:03.056579 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911355
I1015 04:23:03.482378 22464 solver.cpp:191] Iteration 38, loss = 0.227506
I1015 04:23:03.482421 22464 solver.cpp:403] Iteration 38, lr = 1e-05
I1015 04:23:03.482789 22464 solver.cpp:247] Iteration 39, Testing net (#0)
I1015 04:23:09.186048 22464 solver.cpp:285] Test loss: 0.245734
I1015 04:23:09.186115 22464 solver.cpp:298]     Test net output #0: accuracy = 0.914343
I1015 04:23:09.611855 22464 solver.cpp:191] Iteration 39, loss = 0.254487
I1015 04:23:09.611899 22464 solver.cpp:403] Iteration 39, lr = 1e-05
I1015 04:23:09.612257 22464 solver.cpp:247] Iteration 40, Testing net (#0)
I1015 04:23:15.324645 22464 solver.cpp:285] Test loss: 0.246422
I1015 04:23:15.324686 22464 solver.cpp:298]     Test net output #0: accuracy = 0.908864
I1015 04:23:15.750174 22464 solver.cpp:191] Iteration 40, loss = 0.313918
I1015 04:23:15.750218 22464 solver.cpp:403] Iteration 40, lr = 1e-05
I1015 04:23:15.750578 22464 solver.cpp:247] Iteration 41, Testing net (#0)
I1015 04:23:21.463488 22464 solver.cpp:285] Test loss: 0.245104
I1015 04:23:21.463533 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911355
I1015 04:23:21.889647 22464 solver.cpp:191] Iteration 41, loss = 0.315188
I1015 04:23:21.889693 22464 solver.cpp:403] Iteration 41, lr = 1e-05
I1015 04:23:21.890050 22464 solver.cpp:247] Iteration 42, Testing net (#0)
I1015 04:23:27.582859 22464 solver.cpp:285] Test loss: 0.248215
I1015 04:23:27.582905 22464 solver.cpp:298]     Test net output #0: accuracy = 0.910359
I1015 04:23:28.008908 22464 solver.cpp:191] Iteration 42, loss = 0.321685
I1015 04:23:28.008954 22464 solver.cpp:403] Iteration 42, lr = 1e-05
I1015 04:23:28.009312 22464 solver.cpp:247] Iteration 43, Testing net (#0)
I1015 04:23:33.723320 22464 solver.cpp:285] Test loss: 0.243678
I1015 04:23:33.723366 22464 solver.cpp:298]     Test net output #0: accuracy = 0.911853
I1015 04:23:34.149557 22464 solver.cpp:191] Iteration 43, loss = 0.267616
I1015 04:23:34.149602 22464 solver.cpp:403] Iteration 43, lr = 1e-05
I1015 04:23:34.149960 22464 solver.cpp:247] Iteration 44, Testing net (#0)
I1015 04:23:39.843304 22464 solver.cpp:285] Test loss: 0.244982
I1015 04:23:39.843396 22464 solver.cpp:298]     Test net output #0: accuracy = 0.912849
I1015 04:23:40.268277 22464 solver.cpp:191] Iteration 44, loss = 0.177957
I1015 04:23:40.268321 22464 solver.cpp:403] Iteration 44, lr = 1e-05
I1015 04:23:40.268740 22464 solver.cpp:247] Iteration 45, Testing net (#0)
I1015 04:23:45.966486 22464 solver.cpp:285] Test loss: 0.244004
I1015 04:23:45.966531 22464 solver.cpp:298]     Test net output #0: accuracy = 0.916335
I1015 04:23:46.391496 22464 solver.cpp:191] Iteration 45, loss = 0.200623
I1015 04:23:46.391542 22464 solver.cpp:403] Iteration 45, lr = 1e-05
I1015 04:23:46.391901 22464 solver.cpp:247] Iteration 46, Testing net (#0)
